{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe6e7014",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = open('tiny_shakespeare_dataset.txt', 'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd7fde32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSteps:\\n1. Create tokenizer (define dictionary/vocabulary)\\n2. Create encoder (string to ids) and decoder (ids to string) function for tokenizer\\n3. Define the model \\n4. Define an example\\n5. Write a training loop (cost function etc.)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Steps:\n",
    "1. Create tokenizer (define dictionary/vocabulary)\n",
    "2. Create encoder (string to ids) and decoder (ids to string) function for tokenizer\n",
    "3. Define the model \n",
    "4. Define an example\n",
    "5. Write a training loop (cost function etc.)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0ff558",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d76baef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPE:\n",
    "    def __init__(self):\n",
    "        self.merges = {}\n",
    "        self.vocab = {i: bytes([i]) for i in range(256)}\n",
    "\n",
    "    def get_stats(self, ids):\n",
    "        counts = {}\n",
    "        for pair in zip(ids[:-1], ids[1:]):\n",
    "            counts[pair] = counts.get(pair, 0) + 1\n",
    "        return counts\n",
    "\n",
    "    def merge(self, ids, pair, idx):\n",
    "        newids = []\n",
    "        i = 0\n",
    "        while i < len(ids):\n",
    "            if i < len(ids) - 1 and ids[i] == pair[0] and ids[i+1] == pair[1]:\n",
    "                newids.append(idx)\n",
    "                i += 2\n",
    "            else:\n",
    "                newids.append(ids[i])\n",
    "                i += 1\n",
    "        return newids\n",
    "\n",
    "    def train(self, text, vocab_size):\n",
    "        assert vocab_size >= 256\n",
    "        num_merges = vocab_size - 256\n",
    "        ids = list(text.encode(\"utf-8\"))\n",
    "\n",
    "        for i in range(num_merges):\n",
    "            stats = self.get_stats(ids)\n",
    "            if not stats:\n",
    "                break\n",
    "            pair = max(stats, key=stats.get)\n",
    "            idx = 256 + i\n",
    "            \n",
    "            if pair[0] in self.vocab and pair[1] in self.vocab:\n",
    "                self.vocab[idx] = self.vocab[pair[0]] + self.vocab[pair[1]]\n",
    "            \n",
    "            self.merges[pair] = idx\n",
    "            ids = self.merge(ids, pair, idx)\n",
    "\n",
    "    def encode(self, text):\n",
    "        ids = list(text.encode(\"utf-8\"))\n",
    "        while len(ids) >= 2:\n",
    "            stats = self.get_stats(ids)\n",
    "            pair = min(stats, key=lambda p: self.merges.get(p, float(\"inf\")))\n",
    "            if pair not in self.merges:\n",
    "                break\n",
    "            idx = self.merges[pair]\n",
    "            ids = self.merge(ids, pair, idx)\n",
    "        return ids\n",
    "\n",
    "    def decode(self, ids):\n",
    "        tokens = b\"\".join(self.vocab[idx] for idx in ids)\n",
    "        return tokens.decode(\"utf-8\", errors=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "893ec021",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/Users/rithwiknukala/opt/anaconda3/envs/transformersexp/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/Users/rithwiknukala/opt/anaconda3/envs/transformersexp/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/rithwiknukala/opt/anaconda3/envs/transformersexp/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/rithwiknukala/opt/anaconda3/envs/transformersexp/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/rithwiknukala/opt/anaconda3/envs/transformersexp/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/rithwiknukala/opt/anaconda3/envs/transformersexp/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/rithwiknukala/opt/anaconda3/envs/transformersexp/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/rithwiknukala/opt/anaconda3/envs/transformersexp/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/rithwiknukala/opt/anaconda3/envs/transformersexp/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/rithwiknukala/opt/anaconda3/envs/transformersexp/lib/python3.10/site-packages/ipykernel/utils.py\", line 71, in preserve_context\n",
      "    return await f(*args, **kwargs)\n",
      "  File \"/Users/rithwiknukala/opt/anaconda3/envs/transformersexp/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"/Users/rithwiknukala/opt/anaconda3/envs/transformersexp/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/rithwiknukala/opt/anaconda3/envs/transformersexp/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/rithwiknukala/opt/anaconda3/envs/transformersexp/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/rithwiknukala/opt/anaconda3/envs/transformersexp/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/rithwiknukala/opt/anaconda3/envs/transformersexp/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/rithwiknukala/opt/anaconda3/envs/transformersexp/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/rithwiknukala/opt/anaconda3/envs/transformersexp/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/rithwiknukala/opt/anaconda3/envs/transformersexp/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/rithwiknukala/opt/anaconda3/envs/transformersexp/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/rithwiknukala/opt/anaconda3/envs/transformersexp/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/rithwiknukala/opt/anaconda3/envs/transformersexp/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/h4/0x51vfp92vd301ldpfnkf1xw0000gp/T/ipykernel_47325/1338028860.py\", line 1, in <module>\n",
      "    import torch\n",
      "  File \"/Users/rithwiknukala/opt/anaconda3/envs/transformersexp/lib/python3.10/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/rithwiknukala/opt/anaconda3/envs/transformersexp/lib/python3.10/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/rithwiknukala/opt/anaconda3/envs/transformersexp/lib/python3.10/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/rithwiknukala/opt/anaconda3/envs/transformersexp/lib/python3.10/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/rithwiknukala/opt/anaconda3/envs/transformersexp/lib/python3.10/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/rithwiknukala/opt/anaconda3/envs/transformersexp/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        pass\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "    \n",
    "model2 = Model()\n",
    "model2(torch.tensor(5))\n",
    "model2.forward(torch.tensor(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f50e83ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BPE()\n",
    "tokenizer.train(df, vocab_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c520e4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a', 'e')\n"
     ]
    }
   ],
   "source": [
    "print(max(zip(['a', 'b', 'a'], ['e', 'c', 'a', 'g']), key = lambda x: ord(x[0]) + ord(x[1])))\n",
    "# print(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "7e11525c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "cbe781e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'o'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052ca6c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(266, 260)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max(stats.keys(), key = stats.get)\n",
    "max(stats.keys(), key = lambda x: stats[x])\n",
    "# max(list(stats.values()))\n",
    "# max(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7399a255",
   "metadata": {},
   "outputs": [],
   "source": [
    "#decoding\n",
    "bpe_tokenizer = BPE()\n",
    "vocab_size = 500\n",
    "merges = {}\n",
    "num_merges = vocab_size - 256\n",
    "tokens = df.encode('utf-8')\n",
    "# print(tokens[0])\n",
    "# print(tokens)\n",
    "# tokens = list(map(int, tokens))\n",
    "\n",
    "for i in range(num_merges):\n",
    "    stats = bpe_tokenizer.get_stats(tokens)\n",
    "    pair = max(stats, key = stats.get)\n",
    "    idx = 256 + i\n",
    "    tokens = bpe_tokenizer.merge(tokens, pair, idx)\n",
    "    merges[pair] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3482f50b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(101, 32): 256,\n",
       " (116, 104): 257,\n",
       " (116, 32): 258,\n",
       " (115, 32): 259,\n",
       " (100, 32): 260,\n",
       " (44, 32): 261,\n",
       " (111, 117): 262,\n",
       " (101, 114): 263,\n",
       " (105, 110): 264,\n",
       " (121, 32): 265,\n",
       " (97, 110): 266,\n",
       " (58, 10): 267,\n",
       " (111, 114): 268,\n",
       " (111, 32): 269,\n",
       " (101, 110): 270,\n",
       " (10, 10): 271,\n",
       " (97, 114): 272,\n",
       " (32, 257): 273,\n",
       " (111, 110): 274,\n",
       " (108, 108): 275,\n",
       " (104, 97): 276,\n",
       " (44, 10): 277,\n",
       " (46, 271): 278,\n",
       " (105, 259): 279,\n",
       " (101, 115): 280,\n",
       " (121, 262): 281,\n",
       " (32, 115): 282,\n",
       " (116, 269): 283,\n",
       " (266, 260): 284,\n",
       " (111, 119): 285,\n",
       " (101, 97): 286,\n",
       " (32, 109): 287,\n",
       " (32, 119): 288,\n",
       " (111, 102): 289,\n",
       " (32, 104): 290,\n",
       " (264, 103): 291,\n",
       " (111, 109): 292,\n",
       " (32, 97): 293,\n",
       " (99, 104): 294,\n",
       " (257, 256): 295,\n",
       " (115, 116): 296,\n",
       " (32, 98): 297,\n",
       " (110, 111): 298,\n",
       " (105, 114): 299,\n",
       " (102, 268): 300,\n",
       " (118, 256): 301,\n",
       " (101, 261): 302,\n",
       " (105, 257): 303,\n",
       " (273, 256): 304,\n",
       " (115, 101): 305,\n",
       " (108, 105): 306,\n",
       " (84, 104): 307,\n",
       " (275, 32): 308,\n",
       " (114, 101): 309,\n",
       " (115, 258): 310,\n",
       " (97, 258): 311,\n",
       " (65, 110): 312,\n",
       " (73, 32): 313,\n",
       " (101, 272): 314,\n",
       " (105, 109): 315,\n",
       " (105, 116): 316,\n",
       " (111, 111): 317,\n",
       " (103, 104): 318,\n",
       " (97, 116): 319,\n",
       " (105, 115): 320,\n",
       " (108, 101): 321,\n",
       " (263, 32): 322,\n",
       " (262, 114): 323,\n",
       " (312, 260): 324,\n",
       " (39, 259): 325,\n",
       " (101, 101): 326,\n",
       " (298, 258): 327,\n",
       " (109, 265): 328,\n",
       " (59, 10): 329,\n",
       " (114, 97): 330,\n",
       " (46, 10): 331,\n",
       " (281, 114): 332,\n",
       " (117, 114): 333,\n",
       " (276, 258): 334,\n",
       " (114, 105): 335,\n",
       " (117, 258): 336,\n",
       " (108, 260): 337,\n",
       " (289, 32): 338,\n",
       " (79, 267): 339,\n",
       " (101, 260): 340,\n",
       " (108, 97): 341,\n",
       " (105, 258): 342,\n",
       " (114, 111): 343,\n",
       " (263, 256): 344,\n",
       " (101, 259): 345,\n",
       " (100, 261): 346,\n",
       " (117, 110): 347,\n",
       " (69, 78): 348,\n",
       " (107, 256): 349,\n",
       " (121, 261): 350,\n",
       " (73, 78): 351,\n",
       " (32, 100): 352,\n",
       " (63, 271): 353,\n",
       " (97, 259): 354,\n",
       " (102, 97): 355,\n",
       " (119, 303): 356,\n",
       " (276, 301): 357,\n",
       " (83, 267): 358,\n",
       " (32, 99): 359,\n",
       " (87, 104): 360,\n",
       " (257, 311): 361,\n",
       " (270, 116): 362,\n",
       " (257, 101): 363,\n",
       " (99, 101): 364,\n",
       " (115, 104): 365,\n",
       " (109, 97): 366,\n",
       " (32, 112): 367,\n",
       " (257, 263): 368,\n",
       " (98, 101): 369,\n",
       " (46, 32): 370,\n",
       " (65, 82): 371,\n",
       " (99, 256): 372,\n",
       " (291, 32): 373,\n",
       " (97, 108): 374,\n",
       " (59, 32): 375,\n",
       " (257, 262): 376,\n",
       " (115, 261): 377,\n",
       " (109, 256): 378,\n",
       " (115, 256): 379,\n",
       " (108, 111): 380,\n",
       " (99, 107): 381,\n",
       " (119, 104): 382,\n",
       " (105, 108): 383,\n",
       " (39, 260): 384,\n",
       " (73, 339): 385,\n",
       " (110, 285): 386,\n",
       " (105, 275): 387,\n",
       " (98, 256): 388,\n",
       " (101, 275): 389,\n",
       " (114, 286): 390,\n",
       " (32, 116): 391,\n",
       " (116, 261): 392,\n",
       " (262, 337): 393,\n",
       " (101, 10): 394,\n",
       " (287, 265): 395,\n",
       " (118, 263): 396,\n",
       " (99, 292): 397,\n",
       " (104, 256): 398,\n",
       " (32, 283): 399,\n",
       " (32, 73): 400,\n",
       " (101, 108): 401,\n",
       " (85, 358): 402,\n",
       " (111, 108): 403,\n",
       " (100, 105): 404,\n",
       " (32, 103): 405,\n",
       " (97, 265): 406,\n",
       " (116, 263): 407,\n",
       " (97, 264): 408,\n",
       " (32, 281): 409,\n",
       " (307, 256): 410,\n",
       " (108, 256): 411,\n",
       " (105, 274): 412,\n",
       " (32, 102): 413,\n",
       " (114, 117): 414,\n",
       " (105, 102): 415,\n",
       " (101, 109): 416,\n",
       " (266, 100): 417,\n",
       " (84, 269): 418,\n",
       " (105, 318): 419,\n",
       " (272, 256): 420,\n",
       " (117, 112): 421,\n",
       " (277, 324): 422,\n",
       " (104, 315): 423,\n",
       " (101, 100): 424,\n",
       " (105, 308): 425,\n",
       " (268, 100): 426,\n",
       " (105, 294): 427,\n",
       " (108, 265): 428,\n",
       " (317, 260): 429,\n",
       " (85, 67): 430,\n",
       " (285, 110): 431,\n",
       " (104, 279): 432,\n",
       " (351, 71): 433,\n",
       " (32, 284): 434,\n",
       " (99, 274): 435,\n",
       " (110, 101): 436,\n",
       " (97, 121): 437,\n",
       " (101, 278): 438,\n",
       " (114, 292): 439,\n",
       " (105, 100): 440,\n",
       " (117, 115): 441,\n",
       " (262, 110): 442,\n",
       " (65, 78): 443,\n",
       " (109, 266): 444,\n",
       " (97, 103): 445,\n",
       " (69, 82): 446,\n",
       " (79, 82): 447,\n",
       " (101, 258): 448,\n",
       " (114, 280): 449,\n",
       " (305, 108): 450,\n",
       " (290, 279): 451,\n",
       " (101, 277): 452,\n",
       " (101, 116): 453,\n",
       " (99, 97): 454,\n",
       " (32, 264): 455,\n",
       " (115, 276): 456,\n",
       " (33, 10): 457,\n",
       " (69, 84): 458,\n",
       " (84, 334): 459,\n",
       " (112, 111): 460,\n",
       " (113, 117): 461,\n",
       " (257, 265): 462,\n",
       " (33, 271): 463,\n",
       " (109, 268): 464,\n",
       " (117, 108): 465,\n",
       " (110, 269): 466,\n",
       " (97, 109): 467,\n",
       " (273, 101): 468,\n",
       " (65, 267): 469,\n",
       " (118, 270): 470,\n",
       " (98, 265): 471,\n",
       " (115, 10): 472,\n",
       " (115, 112): 473,\n",
       " (75, 433): 474,\n",
       " (290, 315): 475,\n",
       " (257, 279): 476,\n",
       " (273, 279): 477,\n",
       " (104, 263): 478,\n",
       " (273, 311): 479,\n",
       " (111, 257): 480,\n",
       " (63, 10): 481,\n",
       " (274, 103): 482,\n",
       " (66, 336): 483,\n",
       " (280, 258): 484,\n",
       " (111, 261): 485,\n",
       " (98, 336): 486,\n",
       " (32, 289): 487,\n",
       " (70, 268): 488,\n",
       " (115, 117): 489,\n",
       " (288, 303): 490,\n",
       " (117, 116): 491,\n",
       " (274, 256): 492,\n",
       " (97, 275): 493,\n",
       " (73, 67): 494,\n",
       " (270, 100): 495,\n",
       " (79, 76): 496,\n",
       " (100, 269): 497,\n",
       " (73, 288): 498,\n",
       " (292, 256): 499}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbe04bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "# decoding (tokens to string)\n",
    "\n",
    "vocab = {idx: bytes([idx]) for idx in range(256)}\n",
    "for (p0, p1), idx in merges.items():\n",
    "    vocab[idx] = vocab[p0] + vocab[p1]\n",
    "\n",
    "def decode(ids):\n",
    "    tokens = b\"\".join(vocab[idx] for idx in ids)\n",
    "    text = tokens.decode('utf-8', errors = 'replace')\n",
    "    return text\n",
    "\n",
    "print(decode([97]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1418b937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[104, 389, 269, 119, 268, 108, 100, 33]\n"
     ]
    }
   ],
   "source": [
    "# encoding (string to tokens)\n",
    "\n",
    "def encode(text):\n",
    "    tokens = list(text.encode('utf-8'))\n",
    "    while len(tokens) >= 2:\n",
    "        stats = bpe_tokenizer.get_stats(tokens)\n",
    "        pair = min(stats, key=lambda p: merges.get(p, float('inf')))\n",
    "        if pair not in merges:\n",
    "            break # nothing else can be merged\n",
    "        idx = merges[pair]\n",
    "        tokens = bpe_tokenizer.merge(tokens, pair, idx)\n",
    "    return tokens\n",
    "\n",
    "print(encode(\"hello world!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcc10abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class InputEmbeddings(nn.Module):\n",
    "    def __init__(self, d_model: int, vocab_size: int):\n",
    "        '''\n",
    "        args:\n",
    "            d_model: dimensions of the embeddings\n",
    "            vocab_size: the vocab size of our tokenizer\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.d_model = d_model\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.embedding(x) * math.sqrt(self.d_model)\n",
    "    \n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, seq: int, dropout: float):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.seq = seq\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        pe = torch.zeros(seq, d_model)\n",
    "        position = torch.arange(0, seq, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x + (self.pe[:, :x.shape[1], :].requires_grad_(False))\n",
    "        return self.dropout(x)\n",
    "\n",
    "class LayerNormalization(nn.Module):\n",
    "    def __init__(self, features: int, eps: float=10**-6) -> None:\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.alpha = nn.Parameter(torch.ones(features))\n",
    "        self.bias = nn.Parameter(torch.zeros(features))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim = -1, keepdim = True)\n",
    "        std = x.std(dim = -1, keepdim = True)\n",
    "        return self.alpha * (x - mean) / (std + self.eps) + self.bias\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model: int, d_ff: int, dropout: float) -> None:\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear2(self.dropout(torch.relu(self.linear1(x))))\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model: int, h: int, dropout: float):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.h = h\n",
    "        assert d_model % h == 0, \"d_model is not divisible by h\"\n",
    "\n",
    "        self.d_k = d_model // h\n",
    "        self.w_q = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.w_k = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.w_v = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.w_o = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    @staticmethod\n",
    "    def attention(query, key, value, mask, dropout: nn.Dropout):\n",
    "        d_k = query.shape[-1]\n",
    "        attention_scores = (query @ key.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "        if mask is not None:\n",
    "            attention_scores = attention_scores.masked_fill(mask == 0, -1e9)\n",
    "        attention_scores = attention_scores.softmax(dim=-1)\n",
    "        if dropout is not None:\n",
    "            attention_scores = dropout(attention_scores)\n",
    "        return (attention_scores @ value), attention_scores\n",
    "\n",
    "    def forward(self, q, k, v, mask):\n",
    "        query = self.w_q(q)\n",
    "        key = self.w_k(k)\n",
    "        value = self.w_v(v)\n",
    "\n",
    "        query = query.view(query.shape[0], -1, self.h, self.d_k).transpose(1, 2)\n",
    "        key = key.view(key.shape[0], -1, self.h, self.d_k).transpose(1, 2)\n",
    "        value = value.view(value.shape[0], -1, self.h, self.d_k).transpose(1, 2)\n",
    "\n",
    "        x, self.attention_scores = MultiHeadAttention.attention(query, key, value, mask, self.dropout)\n",
    "        \n",
    "        x = x.transpose(1, 2).contiguous().view(x.shape[0], -1, self.h * self.d_k)\n",
    "        return self.w_o(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08687ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualConnection(nn.Module):\n",
    "    def __init__(self, features: int, dropout: float) -> None:\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.norm = LayerNormalization(features)\n",
    "    \n",
    "    def forward(self, x, sublayer):\n",
    "        return x + self.dropout(sublayer(self.norm(x)))\n",
    "\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, features: int, self_attention_block: MultiHeadAttention, feed_forward_block: FeedForward, dropout: float) -> None:\n",
    "        super().__init__()\n",
    "        self.self_attention_block = self_attention_block\n",
    "        self.feed_forward_block = feed_forward_block\n",
    "        self.residual_connections = nn.ModuleList([ResidualConnection(features, dropout) for _ in range(2)])\n",
    "    \n",
    "    def forward(self, x, src_mask):\n",
    "        x = self.residual_connections[0](x, lambda x: self.self_attention_block(x, x, x, src_mask))\n",
    "        x = self.residual_connections[1](x, self.feed_forward_block)\n",
    "        return x\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, features: int, layers: nn.ModuleList) -> None:\n",
    "        super().__init__()\n",
    "        self.layers = layers\n",
    "        self.norm = LayerNormalization(features)\n",
    "    \n",
    "    def forward(self, x, mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x)\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, features: int, self_attention_block: MultiHeadAttention, cross_attention_block: MultiHeadAttention, feed_forward_block: FeedForward, dropout: float) -> None:\n",
    "        super().__init__()\n",
    "        self.self_attention_block = self_attention_block\n",
    "        self.cross_attention_block = cross_attention_block\n",
    "        self.feed_forward_block = feed_forward_block\n",
    "        self.residual_connections = nn.ModuleList([ResidualConnection(features, dropout) for _ in range(3)])\n",
    "\n",
    "    def forward(self, x, encoder_output, src_mask, tgt_mask):\n",
    "        x = self.residual_connections[0](x, lambda x: self.self_attention_block(x, x, x, tgt_mask))\n",
    "        x = self.residual_connections[1](x, lambda x: self.cross_attention_block(x, encoder_output, encoder_output, src_mask))\n",
    "        x = self.residual_connections[2](x, self.feed_forward_block)\n",
    "        return x\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, features: int, layers: nn.ModuleList) -> None:\n",
    "        super().__init__()\n",
    "        self.layers = layers\n",
    "        self.norm = LayerNormalization(features)\n",
    "    \n",
    "    def forward(self, x, encoder_output, src_mask, tgt_mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, encoder_output, src_mask, tgt_mask)\n",
    "        return self.norm(x)\n",
    "\n",
    "class ProjectionLayer(nn.Module):    #linear layer\n",
    "    def __init__(self, d_model, vocab_size):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, x) -> None:\n",
    "        return self.proj(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a4fdd52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, encoder: Encoder, decoder: Decoder, src_embed: InputEmbeddings, tgt_embed, InputEmbeddings, src_pos: PositionalEncoding, tgt_pos: PositionalEncoding, projection_layer: ProjectionLayer) -> None:\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_embed = src_embed\n",
    "        self.tgt_embed = tgt_embed\n",
    "        self.src_pos = src_pos\n",
    "        self.tgt_pos = tgt_pos\n",
    "        self.projection_layer = projection_layer\n",
    "    \n",
    "    def encode(self, src, src_mask):\n",
    "        src = self.src_embed(src)\n",
    "        src = self.src_pos(src)\n",
    "        return self.encoder(src, src_mask)\n",
    "    \n",
    "    def decode(self, encoder_output: torch.Tensor, src_mask: torch.Tensor, tgt: torch.Tensor, tgt_mask: torch.Tensor):\n",
    "        tgt = self.tgt_embed(tgt)\n",
    "        tgt = self.tgt_pos(tgt)\n",
    "        return self.decoder(tgt, encoder_output, src_mask, tgt_mask)\n",
    "\n",
    "    def project(self, x):\n",
    "        return self.projection_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "61aa769d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed tokenizer vocab.\n",
      "ID for [PAD]: 504\n",
      "New Vocab Size: 508\n"
     ]
    }
   ],
   "source": [
    "# Fixing the tokenizer to include special tokens such as the one in the code below.\n",
    "token_to_id = {v: k for k, v in tokenizer.vocab.items()}\n",
    "\n",
    "special_tokens = [\"[PAD]\", \"[SOS]\", \"[EOS]\", \"[UNK]\"]\n",
    "next_id = len(token_to_id)\n",
    "\n",
    "for t in special_tokens:\n",
    "    if t not in token_to_id:\n",
    "        token_to_id[t] = next_id\n",
    "        tokenizer.vocab[next_id] = t.encode(\"utf-8\")\n",
    "        next_id += 1\n",
    "tokenizer.vocab = token_to_id\n",
    "\n",
    "config['vocab_size'] = len(tokenizer.vocab)\n",
    "\n",
    "print(\"Fixed tokenizer vocab.\")\n",
    "print(f\"ID for [PAD]: {tokenizer.vocab['[PAD]']}\")\n",
    "print(f\"New Vocab Size: {config['vocab_size']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d145de1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 6.769915580749512\n",
      "Epoch 2, Loss: 6.576513767242432\n",
      "Epoch 3, Loss: 6.496821403503418\n",
      "Epoch 4, Loss: 6.20886754989624\n",
      "Epoch 5, Loss: 6.171534538269043\n",
      "Epoch 6, Loss: 5.953958034515381\n",
      "Epoch 7, Loss: 5.8166656494140625\n",
      "Epoch 8, Loss: 5.67505407333374\n",
      "Epoch 9, Loss: 5.527266502380371\n",
      "Epoch 10, Loss: 5.407516956329346\n",
      "Epoch 11, Loss: 5.182065010070801\n",
      "Epoch 12, Loss: 5.077295303344727\n",
      "Epoch 13, Loss: 4.883518695831299\n",
      "Epoch 14, Loss: 4.784830570220947\n",
      "Epoch 15, Loss: 4.603269577026367\n",
      "Epoch 16, Loss: 4.3618597984313965\n",
      "Epoch 17, Loss: 4.229440689086914\n",
      "Epoch 18, Loss: 4.0307440757751465\n",
      "Epoch 19, Loss: 3.7889180183410645\n",
      "Epoch 20, Loss: 3.6441268920898438\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "config = {\n",
    "    'd_model': 512,\n",
    "    'vocab_size': len(tokenizer.vocab),\n",
    "    'seq_len': 100,\n",
    "    'd_ff': 2048,\n",
    "    'h': 8, \n",
    "    'dropout': 0.1,\n",
    "    'N': 6,\n",
    "    'batch_size': 8,\n",
    "    'lr': 1e-4,\n",
    "    'num_epochs': 20\n",
    "}\n",
    "\n",
    "def build_transformer(cfg):\n",
    "    src_embed = InputEmbeddings(cfg['d_model'], cfg['vocab_size'])\n",
    "    tgt_embed = InputEmbeddings(cfg['d_model'], cfg['vocab_size'])\n",
    "    src_pos = PositionalEncoding(cfg['d_model'], cfg['seq_len'], cfg['dropout'])\n",
    "    tgt_pos = PositionalEncoding(cfg['d_model'], cfg['seq_len'], cfg['dropout'])\n",
    "    \n",
    "    encoder_blocks = []\n",
    "    for _ in range(cfg['N']):\n",
    "        attn = MultiHeadAttention(cfg['d_model'], cfg['h'], cfg['dropout'])\n",
    "        ff = FeedForward(cfg['d_model'], cfg['d_ff'], cfg['dropout'])\n",
    "        encoder_blocks.append(EncoderBlock(cfg['d_model'], attn, ff, cfg['dropout']))\n",
    "        \n",
    "    decoder_blocks = []\n",
    "    for _ in range(cfg['N']):\n",
    "        self_attn = MultiHeadAttention(cfg['d_model'], cfg['h'], cfg['dropout'])\n",
    "        cross_attn = MultiHeadAttention(cfg['d_model'], cfg['h'], cfg['dropout'])\n",
    "        ff = FeedForward(cfg['d_model'], cfg['d_ff'], cfg['dropout'])\n",
    "        decoder_blocks.append(DecoderBlock(cfg['d_model'], self_attn, cross_attn, ff, cfg['dropout']))\n",
    "        \n",
    "    encoder = Encoder(cfg['d_model'], nn.ModuleList(encoder_blocks))\n",
    "    decoder = Decoder(cfg['d_model'], nn.ModuleList(decoder_blocks))\n",
    "    projection = ProjectionLayer(cfg['d_model'], cfg['vocab_size'])\n",
    "    \n",
    "    return Transformer(encoder, decoder, src_embed, tgt_embed, None, src_pos, tgt_pos, projection)\n",
    "\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, tokenizer, seq_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.seq_len = seq_len\n",
    "        self.data = [\n",
    "            (\"hello world\", \"hello world\"),\n",
    "            (\"goodbye\", \"goodbye\"),\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src_text, tgt_text = self.data[idx]\n",
    "        \n",
    "        enc_input = [tokenizer.vocab['[SOS]']] + tokenizer.encode(src_text) + [tokenizer.vocab['[EOS]']]\n",
    "        dec_input = [tokenizer.vocab['[SOS]']] + tokenizer.encode(tgt_text)\n",
    "        label = tokenizer.encode(tgt_text) + [tokenizer.vocab['[EOS]']]\n",
    "        \n",
    "        def pad(x):\n",
    "            return x + [tokenizer.vocab['[PAD]']] * (self.seq_len - len(x))\n",
    "            \n",
    "        return {\n",
    "            \"encoder_input\": torch.tensor(pad(enc_input), dtype=torch.long),\n",
    "            \"decoder_input\": torch.tensor(pad(dec_input), dtype=torch.long),\n",
    "            \"label\": torch.tensor(pad(label), dtype=torch.long)\n",
    "        }\n",
    "\n",
    "def causal_mask(size):\n",
    "    mask = torch.triu(torch.ones((1, size, size)), diagonal=1).type(torch.int)\n",
    "    return mask == 0\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = build_transformer(config).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'])\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer.vocab['[PAD]'])\n",
    "dataset = TranslationDataset(tokenizer, config['seq_len'])\n",
    "dataloader = DataLoader(dataset, batch_size=config['batch_size'], shuffle=True)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(config['num_epochs']):\n",
    "    for batch in dataloader:\n",
    "        encoder_input = batch['encoder_input'].to(device)\n",
    "        decoder_input = batch['decoder_input'].to(device)\n",
    "        label = batch['label'].to(device)                \n",
    "        src_mask = (encoder_input != tokenizer.vocab['[PAD]']).unsqueeze(1).unsqueeze(2)\n",
    "        tgt_mask = (decoder_input != tokenizer.vocab['[PAD]']).unsqueeze(1).unsqueeze(2)\n",
    "        tgt_mask = tgt_mask & causal_mask(decoder_input.size(1)).to(device)\n",
    "        encoder_output = model.encode(encoder_input, src_mask)\n",
    "        decoder_output = model.decode(encoder_output, src_mask, decoder_input, tgt_mask)\n",
    "        proj_output = model.project(decoder_output)\n",
    "        loss = loss_fn(proj_output.view(-1, config['vocab_size']), label.view(-1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9616d042",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(model, sentence, tokenizer, max_len=50, device='cpu'):\n",
    "    model.eval()\n",
    "    \n",
    "    ids = tokenizer.encode(sentence)\n",
    "    ids = [tokenizer.vocab['[SOS]']] + ids + [tokenizer.vocab['[EOS]']]\n",
    "    \n",
    "    encoder_input = torch.tensor(ids, dtype=torch.long).unsqueeze(0).to(device)\n",
    "    \n",
    "    src_mask = (encoder_input != tokenizer.vocab['[PAD]']).unsqueeze(1).unsqueeze(2).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        encoder_output = model.encode(encoder_input, src_mask)\n",
    "    \n",
    "    decoder_input = torch.tensor([[tokenizer.vocab['[SOS]']]], dtype=torch.long).to(device)\n",
    "\n",
    "    output_tokens = []\n",
    "    \n",
    "    for _ in range(max_len):\n",
    "        tgt_mask = (decoder_input != tokenizer.vocab['[PAD]']).unsqueeze(1).unsqueeze(2)\n",
    "        tgt_mask = tgt_mask & causal_mask(decoder_input.size(1)).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            out = model.decode(encoder_output, src_mask, decoder_input, tgt_mask)\n",
    "            prob = model.project(out[:, -1])\n",
    "            _, next_word = torch.max(prob, dim=1)\n",
    "            next_word_item = next_word.item()\n",
    "\n",
    "        if next_word_item == tokenizer.vocab['[EOS]']:\n",
    "            break\n",
    "            \n",
    "        output_tokens.append(next_word_item)\n",
    "        decoder_input = torch.cat(\n",
    "            [decoder_input, torch.empty(1, 1).type_as(encoder_input).fill_(next_word_item)], dim=1\n",
    "        )\n",
    "\n",
    "    id_to_token = {v: k for k, v in tokenizer.vocab.items()}\n",
    "    decoded_string = []\n",
    "    for i in output_tokens:\n",
    "        t = id_to_token.get(i, b'')\n",
    "        if isinstance(t, bytes):\n",
    "            decoded_string.append(t.decode('utf-8', errors='replace'))\n",
    "        else:\n",
    "            decoded_string.append(str(t))\n",
    "            \n",
    "    return \"\".join(decoded_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "13947655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: hello world\n",
      "Model Output: hello wororororororororororororororororororororororororororye\n"
     ]
    }
   ],
   "source": [
    "# Test Sentence\n",
    "test_sentence = \"hello world\"\n",
    "\n",
    "print(f\"Input: {test_sentence}\")\n",
    "translation = translate(model, test_sentence, tokenizer, device=device)\n",
    "print(f\"Model Output: {translation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973e3d2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformersexp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "64b32914f510e77b327eba8d33892bd2264dd3e5cd2be15a944130165853f5b5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
